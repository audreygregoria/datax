{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X-RwB75m44SL",
    "outputId": "012f3f85-a3ad-49aa-e6a1-cb3b1e5eab0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: anvil-uplink in /usr/local/lib/python3.6/site-packages (0.3.42)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/site-packages (from anvil-uplink) (0.18.2)\n",
      "Requirement already satisfied: ws4py in /usr/local/lib/python3.6/site-packages (from anvil-uplink) (0.5.1)\n",
      "Collecting argparse\n",
      "  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/site-packages (from anvil-uplink) (1.16.0)\n",
      "Installing collected packages: argparse\n",
      "Successfully installed argparse-1.4.0\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: textblob in /usr/local/lib/python3.6/site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.6/site-packages (from textblob) (3.6.7)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/site-packages (from nltk>=3.1->textblob) (4.64.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.6/site-packages (from nltk>=3.1->textblob) (2022.4.24)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/site-packages (from nltk>=3.1->textblob) (8.0.4)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/site-packages (from click->nltk>=3.1->textblob) (4.8.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/site-packages (from importlib-metadata->click->nltk>=3.1->textblob) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.6/site-packages (from importlib-metadata->click->nltk>=3.1->textblob) (4.1.1)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.6/site-packages (from tqdm->nltk>=3.1->textblob) (5.4.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tweepy in /usr/local/lib/python3.6/site-packages (4.6.0)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in /usr/local/lib/python3.6/site-packages (from tweepy) (1.3.1)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in /usr/local/lib/python3.6/site-packages (from tweepy) (3.2.0)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in /usr/local/lib/python3.6/site-packages (from tweepy) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.6/site-packages (from requests<3,>=2.27.0->tweepy) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/site-packages (from requests<3,>=2.27.0->tweepy) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/site-packages (from requests<3,>=2.27.0->tweepy) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.6/site-packages (from requests<3,>=2.27.0->tweepy) (3.3)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: wordcloud in /usr/local/lib/python3.6/site-packages (1.8.1)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.6/site-packages (from wordcloud) (8.4.0)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.6/site-packages (from wordcloud) (1.19.5)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/site-packages (from wordcloud) (3.3.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/site-packages (from matplotlib->wordcloud) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/site-packages (from matplotlib->wordcloud) (3.0.8)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib->wordcloud) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: config in /usr/local/lib/python3.6/site-packages (0.5.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install anvil-uplink\n",
    "!pip install textblob\n",
    "!pip install tweepy\n",
    "!pip install wordcloud\n",
    "!pip install config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to wss://anvil.works/uplink\n",
      "Anvil websocket open\n",
      "Connected to \"Published\" as SERVER\n"
     ]
    }
   ],
   "source": [
    "import anvil.server\n",
    "anvil.server.connect('server_57AQBXHXBXQB3SV63LDEGSMA-UP4OJMY33G3H35TG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import config\n",
    "from textblob import TextBlob\n",
    "import tweepy\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re \n",
    "import pandas as pd\n",
    "import tweepy \n",
    "from tweepy import OAuthHandler \n",
    "from textblob import TextBlob \n",
    "import csv\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "n_words= set(stopwords.words('english'))\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "porter = PorterStemmer()\n",
    "\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bwYZGQs35nuo"
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "api_key = 'N00JfH3Y4zMrtYxCNPbqiWXfb'\n",
    "api_key_secret = 'Gh1SwlftMFJjjMEpCPtaw0ai1lnWHrSOPlJEPO42JBE5FVaspN'\n",
    "access_token = '1453279345292816394-pcM7tZ81qLxrw02UwhpuZVQiuzTkL3'\n",
    "access__token_secret = 'n9rCrffxa4SBov2cgXaDYtFEjt715JP45pbIqPiZWdjSY'\n",
    "bearer_token = 'AAAAAAAAAAAAAAAAAAAAAPcmcAEAAAAACC8mIptctcONcVXXg5Zvh%2BkT4sY%3DrCtUvDowB8H2uY4jjOl6u5gUvogRe19XwvqPAn2ChxHDngPOur'\n",
    "client = tweepy.Client(bearer_token=bearer_token,\n",
    "                           consumer_key=api_key,\n",
    "                           consumer_secret=api_key_secret,\n",
    "                           access_token=access_token,\n",
    "                           access_token_secret=access__token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lUDDjF-e7Vt7"
   },
   "outputs": [],
   "source": [
    "auth_handler = tweepy.OAuthHandler(consumer_key=api_key, consumer_secret=api_key_secret)\n",
    "auth_handler.set_access_token(access_token, access__token_secret)\n",
    "\n",
    "api = tweepy.API(auth_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "yoeqrcEB-MPX"
   },
   "outputs": [],
   "source": [
    "search_term = 'bored apes'\n",
    "tweet_amount = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HOIJhrdrpTss"
   },
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "  # removing @ tags and links from the text\n",
    "  text= ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t]) |(\\w+:\\/\\/\\S+)\", \" \", text).split()) \n",
    "  # converting all letters to lower case and relacing '-' with spaces.\n",
    "  text= text.lower().replace('-', ' ')\n",
    "  # removing stowards and numbers\n",
    "  table= str.maketrans('', '', string.punctuation+string.digits)\n",
    "  text= text.translate(table)\n",
    "  # tokenizing words\n",
    "  tokens = word_tokenize(text)\n",
    "  # stemming the words \n",
    "  stemmed = [porter.stem(word) for word in tokens]\n",
    "  words = [w for w in stemmed if not w in n_words]\n",
    "  # lemmetizing words\n",
    "  # lemme= [lemmatizer.lemmatize(word) for word in tokens]\n",
    "  # words = [w for w in lemme if not w in n_words]\n",
    "  text = ' '.join(words)\n",
    "  return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@anvil.server.callable\n",
    "def wordcloud_draw(data, color = 'black'):\n",
    "    words = ' '.join(data)\n",
    "    cleaned_word = \" \".join([word for word in words.split()\n",
    "                            if 'http' not in word  # double check for nay links\n",
    "                                and not word.startswith('#')  # removing hash tags\n",
    "                                and word != 'rt'  \n",
    "                            ])\n",
    "    wordcloud = WordCloud(stopwords=STOPWORDS, # using stopwords provided by Word cloud its optional since we already removed stopwords :)\n",
    "                      background_color=color,\n",
    "                      width=2500,\n",
    "                      height=2000\n",
    "                     ).generate(cleaned_word)\n",
    "    # using matplotlib to display the images in notebook itself.\n",
    "    plt.figure(1,figsize=(13, 13))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis('off')\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "2B25k3N8a-sQ"
   },
   "outputs": [],
   "source": [
    "@anvil.server.callable\n",
    "def sentiment(search_term): \n",
    "  tweet_amount = 100\n",
    "  #tweets = tweepy.Cursor(api.search_recent_tweets, q= search_term, lang = 'en', wait_on_rate_limit=True).items(tweet_amount)\n",
    "  tweets = client.search_recent_tweets(query=search_term, max_results=tweet_amount)[0]\n",
    "  tweetss=[]\n",
    "  for tweet in tweets:\n",
    "      tweet= clean(tweet.text)\n",
    "      analysis = TextBlob(tweet)\n",
    "      senti= analysis.sentiment.polarity\n",
    "      if senti<0 :\n",
    "        emotion = \"NEG\"\n",
    "      elif senti>0:\n",
    "        emotion= \"POS\"\n",
    "      else:\n",
    "        emotion= \"NEU\"\n",
    "      tweetss.append((tweet, senti, emotion))\n",
    "  df= pd.DataFrame(tweetss, columns= ['tweets', 'senti', 'emotion'])\n",
    "  # droping retweets\n",
    "  df= df.drop_duplicates()\n",
    "  # saving to CSV file\n",
    "  df.to_csv('data.csv', index= False)\n",
    "  df_neu= df[ df['emotion'] == 'NEU']\n",
    "  df_neu= df_neu['tweets']\n",
    "  df_pos = df[ df['emotion'] == 'POS']\n",
    "  df_pos = df_pos['tweets']\n",
    "  df_neg = df[ df['emotion'] == 'NEG']\n",
    "  df_neg = df_neg['tweets']\n",
    "\n",
    "  ratio_pos= len(df_pos)/len(df)\n",
    "  ratio_neg= len(df_neg)/len(df)\n",
    "  ratio_neu= len(df_neu)/len(df)\n",
    "\n",
    "  percent_pos = ratio_pos * 100\n",
    "  percent_neg = ratio_neg * 100 \n",
    "  percent_neu = ratio_neu * 100 \n",
    "  return [percent_pos, percent_neg, percent_neu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20.967741935483872, 12.903225806451612, 66.12903225806451]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment(search_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "I9yo_en_rcXB"
   },
   "outputs": [],
   "source": [
    "@anvil.server.callable\n",
    "def pos(search_term): \n",
    "  pos_result = sentiment(search_term)\n",
    "  return pos_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oHh3Twtzqapv",
    "outputId": "b6cf43e0-eca8-41b5-9016-f9241a5e813d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.755102040816325"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos('try')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "I7EW-sm5tPId"
   },
   "outputs": [],
   "source": [
    "@anvil.server.callable\n",
    "def neg(search_term): \n",
    "  neg_result = sentiment(search_term)\n",
    "  return neg_result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "FjDD5ozstqOX"
   },
   "outputs": [],
   "source": [
    "@anvil.server.callable\n",
    "def neu(search_term): \n",
    "  neu_result = sentiment(search_term)\n",
    "  return neu_result[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S0fU-hbkttb7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "NFT_Tweets_sentiment_analysis .ipynb",
   "provenance": []
  },
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Base Python)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/python-3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
